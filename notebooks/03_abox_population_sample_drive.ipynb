{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 03 \u2014 Populate a sample A-box (Subjects, Visits, Observations)\n\nThis notebook builds a **small A-box** from a demo longitudinal table (PPMI-like), using:\n\n- the bridge ontology: `ontologies/ppmi_bridge.ttl`\n- the mapping file: `mapping/ppmi_pdon_pmdo_mapping.csv`\n\nIt creates:\n- `ppmi:Subject` individuals (by `PATNO`)\n- `ppmi:Visit` individuals (by `PATNO` + `EVENT_ID`)\n- `ppmi:Observation` individuals for mapped variables\n- `ppmi:DiagnosisObservation` for PRIMDIAG codes\n\n**Output**: `output/ppmi_abox_sample.ttl`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "!pip -q install rdflib pandas owlrl"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Project root (Drive recommended)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\nUSE_DRIVE = True\nif USE_DRIVE:\n  from google.colab import drive\n  drive.mount('/content/drive')\n  PROJECT_DIR = Path('/content/drive/MyDrive/ppmi-ontology-alignment')\nelse:\n  PROJECT_DIR = Path('/content/ppmi-ontology-alignment')\n\nONT_DIR = PROJECT_DIR / 'ontologies'\nMAP_DIR = PROJECT_DIR / 'mapping'\nDATA_DIR = PROJECT_DIR / 'data'\nOUT_DIR = PROJECT_DIR / 'output'\nfor p in [ONT_DIR, MAP_DIR, DATA_DIR, OUT_DIR]:\n  p.mkdir(parents=True, exist_ok=True)\n\nBRIDGE_PATH = ONT_DIR / 'ppmi_bridge.ttl'\nMAP_PATH    = MAP_DIR / 'ppmi_pdon_pmdo_mapping.csv'\nDEMO_PATH   = DATA_DIR / 'ppmi_demo.tsv'\nABOX_OUT    = OUT_DIR / 'ppmi_abox_sample.ttl'\n\nprint('PROJECT_DIR:', PROJECT_DIR)\nprint('Bridge exists :', BRIDGE_PATH.exists(), BRIDGE_PATH)\nprint('Mapping exists:', MAP_PATH.exists(), MAP_PATH)\nprint('Demo exists   :', DEMO_PATH.exists(), DEMO_PATH)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Load mapping CSV"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom google.colab import files\nimport shutil\n\nif not MAP_PATH.exists():\n  print('Upload ppmi_pdon_pmdo_mapping.csv')\n  up = files.upload()\n  for fn in up.keys():\n    shutil.move(f'/content/{fn}', str(MAP_PATH if fn=='ppmi_pdon_pmdo_mapping.csv' else (MAP_DIR/fn)))\n\nmapping = pd.read_csv(MAP_PATH)\nmapping['Variable'] = mapping['Variable'].astype(str).str.strip()\nmapping['TargetIRI'] = mapping['TargetIRI'].astype(str).str.strip()\nmapping.head(10)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Provide / upload demo longitudinal data\n\nExpected format: **TSV** with one row per (PATNO, EVENT_ID).\n\nSave as `data/ppmi_demo.tsv` (tab-separated)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from google.colab import files\nimport shutil\n\nif not DEMO_PATH.exists():\n  print('Upload ppmi_demo.tsv (tab-separated)')\n  up = files.upload()\n  for fn in up.keys():\n    dest = DEMO_PATH if fn=='ppmi_demo.tsv' else (DATA_DIR/fn)\n    shutil.move(f'/content/{fn}', str(dest))\n  print('Saved to:', DEMO_PATH)\n\ndemo = pd.read_csv(DEMO_PATH, sep='\\t')\ndemo.head(3)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Build A-box (RDF)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from rdflib import Graph, Namespace, URIRef, Literal\nfrom rdflib.namespace import RDF, RDFS, OWL, XSD\nimport re\n\nPPMI = Namespace('http://example.org/ppmi-ontology-alignment#')\n\ndef mint_subject(patno: str) -> URIRef:\n  return PPMI[f'subject/{patno}']\n\ndef mint_visit(patno: str, event_id: str) -> URIRef:\n  return PPMI[f'visit/{patno}/{event_id}']\n\ndef mint_obs(patno: str, event_id: str, var: str) -> URIRef:\n  safe = re.sub(r'[^A-Za-z0-9_\\-\\.]+','_', var)\n  return PPMI[f'obs/{patno}/{event_id}/{safe}']\n\ndef parse_gYearMonth(s: str):\n  m = re.match(r'^(\\d{1,2})/(\\d{4})$', s.strip())\n  if not m:\n    return None\n  mm, yy = int(m.group(1)), int(m.group(2))\n  if mm < 1 or mm > 12:\n    return None\n  return f'{yy:04d}-{mm:02d}'\n\ndef literal_best(x):\n  import pandas as pd\n  if pd.isna(x):\n    return None\n  s = str(x).strip()\n  if s == '':\n    return None\n  if re.fullmatch(r'[-+]?\\d+', s):\n    try:\n      return Literal(int(s), datatype=XSD.integer)\n    except Exception:\n      pass\n  if re.fullmatch(r'[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?', s) or re.fullmatch(r'[-+]?\\d+\\.\\d*', s):\n    try:\n      return Literal(float(s), datatype=XSD.decimal)\n    except Exception:\n      pass\n  return Literal(s, datatype=XSD.string)\n\n# Lookup: variable -> target IRI\nmap_rows = mapping.copy()\ndef _clean(v):\n  if v is None:\n    return ''\n  s = str(v).strip()\n  return '' if s.lower()=='nan' else s\n\nvar2target = {}\nfor _, r in map_rows.iterrows():\n  var = _clean(r.get('Variable'))\n  tgt = _clean(r.get('TargetIRI'))\n  if var and tgt:\n    var2target[var] = tgt\n\ndatscan_vars = set(map_rows.loc[map_rows['Category'].astype(str).str.upper().eq('DATSCAN'), 'Variable'].astype(str))\nobs_vars = sorted(set(map_rows.loc[map_rows['MappingBucket'].astype(str).str.upper().isin(['PMDO','MDO','PDON','PPMI/PMDO']), 'Variable'].astype(str)))\n\ng = Graph()\ng.bind('ppmi', PPMI)\ng.bind('rdf', RDF)\ng.bind('rdfs', RDFS)\ng.bind('owl', OWL)\ng.bind('xsd', XSD)\n\nC_Subject = PPMI['Subject']\nC_Visit = PPMI['Visit']\nC_Obs = PPMI['Observation']\nC_DxObs = PPMI['DiagnosisObservation']\nC_ImgObs = PPMI['ImagingObservation']\n\nP_hasVisit = PPMI['hasVisit']\nP_hasObs = PPMI['hasObservation']\nP_observes = PPMI['observesConcept']\nP_refersPdon = PPMI['refersToPdonConcept']\nP_relRegion = PPMI['relatesToRegion']\n\nP_hasValue = PPMI['hasValue']\nP_hasCode  = PPMI['hasCode']\nP_hasDecode= PPMI['hasDecode']\nP_visitDate= PPMI['visitDate']\nP_visitYear= PPMI['visitYear']\nP_ageAtVisit=PPMI['ageAtVisit']\n\nSUBJECT_META = ['COHORT','subgroup','SEX','EDUCYRS','fampd_bin']\n\ndef add_subject_meta(subj, row):\n  for v in SUBJECT_META:\n    if v in row.index:\n      lit = literal_best(row[v])\n      if lit is not None:\n        g.add((subj, PPMI[f'subjectMeta/{v}'], lit))\n\ndef add_visit_meta(visit, row):\n  if 'visit_date' in row.index:\n    s = str(row['visit_date']).strip() if not pd.isna(row['visit_date']) else ''\n    gy = parse_gYearMonth(s)\n    if gy:\n      g.add((visit, P_visitDate, Literal(gy, datatype=XSD.gYearMonth)))\n    elif s:\n      g.add((visit, P_visitDate, Literal(s, datatype=XSD.string)))\n  if 'YEAR' in row.index:\n    lit = literal_best(row['YEAR'])\n    if lit is not None:\n      g.add((visit, P_visitYear, lit))\n  if 'age_at_visit' in row.index:\n    lit = literal_best(row['age_at_visit'])\n    if lit is not None:\n      g.add((visit, P_ageAtVisit, lit))\n\nSAMPLE_PATNO = str(demo['PATNO'].iloc[0])\nsample_df = demo[demo['PATNO'].astype(str) == SAMPLE_PATNO].copy()\nprint('Sample PATNO:', SAMPLE_PATNO, 'rows:', len(sample_df))\n\nfor _, row in sample_df.iterrows():\n  patno = str(row['PATNO']).strip()\n  event = str(row['EVENT_ID']).strip()\n  subj = mint_subject(patno)\n  visit = mint_visit(patno, event)\n\n  g.add((subj, RDF.type, C_Subject))\n  g.add((visit, RDF.type, C_Visit))\n  g.add((subj, P_hasVisit, visit))\n  add_subject_meta(subj, row)\n  add_visit_meta(visit, row)\n\n  for var in obs_vars:\n    if var not in row.index:\n      continue\n    val_lit = literal_best(row[var])\n    if val_lit is None:\n      continue\n\n    obs = mint_obs(patno, event, var)\n    g.add((visit, P_hasObs, obs))\n\n    if var == 'PRIMDIAG':\n      g.add((obs, RDF.type, C_DxObs))\n      g.add((obs, P_hasCode, val_lit))\n      code_str = str(row[var]).strip()\n      try:\n        code_norm = f\"{float(code_str):.1f}\" if re.fullmatch(r'[-+]?\\d+(?:\\.\\d+)?', code_str) else code_str\n      except Exception:\n        code_norm = code_str\n      m = map_rows[(map_rows['Variable']=='PRIMDIAG') & (map_rows['Code'].astype(str).str.strip()==code_norm)]\n      if len(m)==1:\n        tgt = _clean(m.iloc[0].get('TargetIRI'))\n        if tgt:\n          g.add((obs, P_refersPdon, URIRef(tgt)))\n      continue\n\n    if var in datscan_vars and var.startswith('MIA_'):\n      g.add((obs, RDF.type, C_ImgObs))\n      tgt = var2target.get(var)\n      if tgt:\n        g.add((obs, P_relRegion, URIRef(tgt)))\n    else:\n      g.add((obs, RDF.type, C_Obs))\n\n    g.add((obs, P_hasValue, val_lit))\n    tgt = var2target.get(var)\n    if tgt:\n      g.add((obs, P_observes, URIRef(tgt)))\n\nprint('A-box triples:', len(g))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Serialise A-box to Turtle"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "g.serialize(destination=str(ABOX_OUT), format='turtle')\nprint('Wrote:', ABOX_OUT)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Quick check (SPARQL)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "q = '''\nPREFIX ppmi: <http://example.org/ppmi-ontology-alignment#>\nSELECT ?obs ?val ?concept\nWHERE {\n  ?visit ppmi:hasObservation ?obs .\n  OPTIONAL { ?obs ppmi:hasValue ?val }\n  OPTIONAL { ?obs ppmi:observesConcept ?concept }\n}\nLIMIT 50\n'''\nfor row in g.query(q):\n  print(row)\n"
    }
  ],
  "metadata": {
    "colab": {
      "name": "03_abox_population_sample_drive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}