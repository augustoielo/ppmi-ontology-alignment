{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 01 â€” Parse PDON & PMDO ontologies (Colab)\n\nThis notebook loads **PDON** and **PMDO** from local files, validates parsing, extracts basic statistics (classes/properties), and optionally exports Turtle versions for easier downstream work.\n\n**Inputs** (place in `ontologies/`):\n- `pdon.xrdf`\n- `pmdo.xrdf`\n\n**Outputs** (written to `output/`):\n- `pdon.ttl` (optional)\n- `pmdo.ttl` (optional)\n- `ontologies_summary.csv`\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0) Install dependencies"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "!pip -q install rdflib pandas owlrl"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Project folders\n\nIn Colab, we work under `/content`. If you cloned the GitHub repo, set `PROJECT_DIR` accordingly.\nOtherwise, this notebook will create a minimal folder structure.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\n\n# If you cloned the repo, set PROJECT_DIR = Path('/content/ppmi-ontology-alignment')\nPROJECT_DIR = Path('/content/ppmi-ontology-alignment')\n\n# Fallback (no clone): use /content and create project-like folders\nif not PROJECT_DIR.exists():\n    PROJECT_DIR = Path('/content/ppmi-ontology-alignment')\n    PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n\nONTO = PROJECT_DIR / 'ontologies'\nDATA = PROJECT_DIR / 'data'\nOUT  = PROJECT_DIR / 'output'\n\nfor p in [ONTO, DATA, OUT]:\n    p.mkdir(parents=True, exist_ok=True)\n\nPROJECT_DIR, ONTO, DATA, OUT\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Upload files (if needed)\n\nIf `pdon.xrdf` and `pmdo.xrdf` are already in `ontologies/`, you can skip this step.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from google.colab import files\nimport shutil\nfrom pathlib import Path\n\nrequired = ['pdon.xrdf', 'pmdo.xrdf']\n\nmissing = [f for f in required if not (ONTO / f).exists()]\nprint(\"Missing:\", missing)\n\nif missing:\n    uploaded = files.upload()\n    for fname in uploaded.keys():\n        src = Path('/content') / fname\n        dst = ONTO / fname\n        shutil.move(str(src), str(dst))\n    print(\"Uploaded to:\", ONTO)\nelse:\n    print(\"All required ontology files are present in:\", ONTO)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Robust parsing with rdflib\n\n`.xrdf` is not a standard extension, so we try common RDF/OWL formats.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from rdflib import Graph\n\ndef load_graph(path: Path):\n    g = Graph()\n    tried = []\n    for fmt in [\"xml\", \"application/rdf+xml\", \"turtle\", \"n3\", \"nt\"]:\n        try:\n            g.parse(str(path), format=fmt)\n            return g, fmt, tried\n        except Exception as e:\n            tried.append((fmt, str(e)[:200]))\n            continue\n    # last attempt: autodetect\n    g.parse(str(path))\n    return g, \"auto\", tried\n\npdon_path = ONTO / \"pdon.xrdf\"\npmdo_path = ONTO / \"pmdo.xrdf\"\n\npdon_g, pdon_fmt, pdon_tried = load_graph(pdon_path)\npmdo_g, pmdo_fmt, pmdo_tried = load_graph(pmdo_path)\n\nprint(\"PDON triples:\", len(pdon_g), \"format:\", pdon_fmt)\nprint(\"PMDO triples:\", len(pmdo_g), \"format:\", pmdo_fmt)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Extract basic ontology statistics\n\nWe count OWL classes and properties, and extract ontology IRI(s) if present.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom rdflib.namespace import RDF, RDFS, OWL\n\ndef ontology_stats(g: Graph, name: str):\n    ont_iris = list(g.subjects(RDF.type, OWL.Ontology))\n    classes  = set(g.subjects(RDF.type, OWL.Class))\n    objp     = set(g.subjects(RDF.type, OWL.ObjectProperty))\n    datap    = set(g.subjects(RDF.type, OWL.DatatypeProperty))\n    annp     = set(g.subjects(RDF.type, OWL.AnnotationProperty))\n    return {\n        \"ontology\": name,\n        \"triples\": len(g),\n        \"ontology_iris\": \";\".join(str(x) for x in ont_iris[:10]),\n        \"n_classes\": len(classes),\n        \"n_object_properties\": len(objp),\n        \"n_datatype_properties\": len(datap),\n        \"n_annotation_properties\": len(annp),\n    }\n\nstats = pd.DataFrame([\n    ontology_stats(pdon_g, \"PDON\"),\n    ontology_stats(pmdo_g, \"PMDO\"),\n])\n\nstats\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Save summary to CSV"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "summary_csv = OUT / \"ontologies_summary.csv\"\nstats.to_csv(summary_csv, index=False)\nsummary_csv\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Quick label search helpers\n\nUseful for locating candidate classes/properties by `rdfs:label`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def find_by_label(g: Graph, query: str, limit: int = 25):\n    q = query.lower()\n    hits = []\n    for s, _, o in g.triples((None, RDFS.label, None)):\n        if q in str(o).lower():\n            hits.append((str(s), str(o)))\n            if len(hits) >= limit:\n                break\n    return pd.DataFrame(hits, columns=[\"iri\", \"label\"])\n\n# Example searches (edit freely)\nfind_by_label(pdon_g, \"parkinson\", limit=10)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Optional: export Turtle versions\n\nThis can make later processing easier. Turtle files are written to `output/`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "pdon_ttl = OUT / \"pdon.ttl\"\npmdo_ttl = OUT / \"pmdo.ttl\"\n\npdon_g.serialize(destination=str(pdon_ttl), format=\"turtle\")\npmdo_g.serialize(destination=str(pmdo_ttl), format=\"turtle\")\n\npdon_ttl, pmdo_ttl\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Next notebook\n\nProceed to `02_build_bridge_ontology.ipynb` to create the **bridge ontology** with:\n- `owl:imports` to PDON and PMDO\n- minimal T-box for Subject/Visit/Observation\n- mapping scaffolding for PPMI variables\n"
    }
  ],
  "metadata": {
    "colab": {
      "name": "01_parse_ontologies.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
