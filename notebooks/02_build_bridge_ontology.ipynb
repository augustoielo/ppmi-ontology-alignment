{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 — Build bridge ontology (PPMI ↔ PDON/PMDO)\n\n",
        "This notebook creates a non-destructive **bridge ontology** that:\n\n",
        "- imports PDON and PMDO (as-is)\n",
        "- defines a minimal T-box for Subject/Visit/Observation\n",
        "- records the PPMI→ontology mapping from `mapping/ppmi_pdon_pmdo_mapping.csv`\n",
        "- serialises the bridge ontology to `ontologies/ppmi_bridge.ttl`\n\n",
        "It is Drive-friendly and shareable: it will mount Drive and use the same `ppmi-ontology-alignment` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "!pip -q install rdflib pandas owlrl\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Project root (Drive recommended)\n\nThis ensures paths remain stable even if you open this notebook in a fresh Colab runtime.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nimport os\n\nUSE_DRIVE = True  # set False to work in /content only\n\nif USE_DRIVE:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    PROJECT_DIR = Path('/content/drive/MyDrive/ppmi-ontology-alignment')\nelse:\n    PROJECT_DIR = Path('/content/ppmi-ontology-alignment')\n\nPROJECT_DIR.mkdir(parents=True, exist_ok=True)\nONT_DIR = PROJECT_DIR / 'ontologies'\nMAP_DIR = PROJECT_DIR / 'mapping'\nOUT_DIR = PROJECT_DIR / 'output'\n\nfor p in [ONT_DIR, MAP_DIR, OUT_DIR]:\n    p.mkdir(parents=True, exist_ok=True)\n\nMAP_PATH = MAP_DIR / 'ppmi_pdon_pmdo_mapping.csv'\nOUT_PATH = ONT_DIR / 'ppmi_bridge.ttl'\n\nPDON_PATH = ONT_DIR / 'pdon.xrdf'\nPMDO_PATH = ONT_DIR / 'pmdo.xrdf'\n\nprint('PROJECT_DIR:', PROJECT_DIR)\nprint('Exists PDON   :', PDON_PATH.exists(), PDON_PATH)\nprint('Exists PMDO   :', PMDO_PATH.exists(), PMDO_PATH)\nprint('Exists mapping:', MAP_PATH.exists(), MAP_PATH)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Load mapping CSV\n\nIf the file is missing, upload it and it will be moved into `mapping/`.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import pandas as pd\nfrom google.colab import files\nimport shutil\n\nif not MAP_PATH.exists():\n    print('Mapping CSV not found. Please upload ppmi_pdon_pmdo_mapping.csv')\n    uploaded = files.upload()\n    for fname in uploaded.keys():\n        src = Path('/content') / fname\n        dst = MAP_PATH if fname == 'ppmi_pdon_pmdo_mapping.csv' else (MAP_DIR / fname)\n        shutil.move(str(src), str(dst))\n    print('Uploaded to:', MAP_DIR)\n\nmapping = pd.read_csv(MAP_PATH)\nmapping.head(10)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Load PDON and PMDO graphs (robust parser)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from rdflib import Graph\n\ndef load_graph(path: Path):\n    g = Graph()\n    tried = []\n    for fmt in ['xml', 'application/rdf+xml', 'turtle', 'n3', 'nt']:\n        try:\n            g.parse(str(path), format=fmt)\n            return g, fmt, tried\n        except Exception as e:\n            tried.append((fmt, str(e)[:220]))\n            continue\n    g.parse(str(path))\n    return g, 'auto', tried\n\npdon_g, pdon_fmt, _ = load_graph(PDON_PATH)\npmdo_g, pmdo_fmt, _ = load_graph(PMDO_PATH)\n\nprint('PDON triples:', len(pdon_g), 'format:', pdon_fmt)\nprint('PMDO triples:', len(pmdo_g), 'format:', pmdo_fmt)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Extract ontology IRI(s)\n\nWe use the IRI declared as `owl:Ontology` when present; otherwise we fall back to common defaults.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from rdflib.namespace import RDF, OWL\n\ndef get_ontology_iris(g: Graph):\n    return sorted({str(s) for s in g.subjects(RDF.type, OWL.Ontology)})\n\npdon_iris = get_ontology_iris(pdon_g)\npmdo_iris = get_ontology_iris(pmdo_g)\n\nPDON_IMPORT_IRI = pdon_iris[0] if pdon_iris else 'http://www.semanticweb.org/ontologies/2011/1/Ontology1296772722296.owl'\nPMDO_IMPORT_IRI = pmdo_iris[0] if pmdo_iris else 'http://www.case.edu/PMDO'\n\nprint('PDON import IRI:', PDON_IMPORT_IRI)\nprint('PMDO import IRI:', PMDO_IMPORT_IRI)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Create bridge ontology header + imports\n\nSet your final namespace later; for now we keep a stable placeholder.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from rdflib import Graph, Namespace, URIRef, Literal\nfrom rdflib.namespace import RDF, RDFS, OWL, XSD\n\nbridge = Graph()\n\nPPMI = Namespace('http://example.org/ppmi-ontology-alignment#')  # replace later\nbridge.bind('ppmi', PPMI)\nbridge.bind('owl', OWL)\nbridge.bind('rdfs', RDFS)\nbridge.bind('rdf', RDF)\nbridge.bind('xsd', XSD)\n\nBRIDGE_IRI = URIRef('http://example.org/ppmi-ontology-alignment')  # replace later\nbridge.add((BRIDGE_IRI, RDF.type, OWL.Ontology))\nbridge.add((BRIDGE_IRI, RDFS.label, Literal('PPMI–PDON/PMDO bridge ontology')))\nbridge.add((BRIDGE_IRI, RDFS.comment, Literal('Non-destructive bridge ontology for mapping PPMI longitudinal variables to PDON and PMDO concepts.')))\n\nbridge.add((BRIDGE_IRI, OWL.imports, URIRef(PDON_IMPORT_IRI)))\nbridge.add((BRIDGE_IRI, OWL.imports, URIRef(PMDO_IMPORT_IRI)))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Minimal T-box (Subject, Visit, Observation)\n\nThese are **your** classes/properties, independent from PDON/PMDO. PDON/PMDO are reused via imports.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Classes\nfor cls, label in [\n    ('Subject', 'Subject (PPMI participant)'),\n    ('Visit', 'Visit (PPMI timepoint)'),\n    ('Observation', 'Observation / measurement at a visit'),\n    ('DiagnosisObservation', 'Diagnosis observation (coded)'),\n    ('ImagingObservation', 'Imaging-derived observation'),\n]:\n    c = PPMI[cls]\n    bridge.add((c, RDF.type, OWL.Class))\n    bridge.add((c, RDFS.label, Literal(label)))\n\ndef add_objprop(local, domain, range_, label):\n    p = PPMI[local]\n    bridge.add((p, RDF.type, OWL.ObjectProperty))\n    bridge.add((p, RDFS.domain, PPMI[domain]))\n    bridge.add((p, RDFS.range, range_))\n    bridge.add((p, RDFS.label, Literal(label)))\n    return p\n\nadd_objprop('hasVisit', 'Subject', PPMI['Visit'], 'has visit')\nadd_objprop('hasObservation', 'Visit', PPMI['Observation'], 'has observation')\nadd_objprop('observesConcept', 'Observation', OWL.Thing, 'observes concept (PDON/PMDO/MDO class)')\nadd_objprop('refersToPdonConcept', 'DiagnosisObservation', OWL.Thing, 'refers to PDON concept')\nadd_objprop('relatesToRegion', 'ImagingObservation', OWL.Thing, 'relates to anatomical region (e.g., MDO)')\n\ndef add_dataprop(local, domain, range_, label):\n    p = PPMI[local]\n    bridge.add((p, RDF.type, OWL.DatatypeProperty))\n    bridge.add((p, RDFS.domain, PPMI[domain]))\n    bridge.add((p, RDFS.range, range_))\n    bridge.add((p, RDFS.label, Literal(label)))\n    return p\n\n# Keep value as string at bridge level; you can specialise later per variable\nadd_dataprop('hasValue', 'Observation', XSD.string, 'has value (literal)')\nadd_dataprop('hasCode', 'Observation', XSD.string, 'has code (categorical/ordinal)')\nadd_dataprop('hasDecode', 'Observation', XSD.string, 'has decode (human label)')\n\n# Visit metadata\nadd_dataprop('visitDate', 'Visit', XSD.string, 'visit date (raw)')\nadd_dataprop('visitYear', 'Visit', XSD.integer, 'visit year index')\nadd_dataprop('ageAtVisit', 'Visit', XSD.decimal, 'age at visit')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Embed mapping as annotation triples\n\nWe store mapping rows as resources under `ppmi:mapping/<Variable>`.\n\nThis keeps provenance and avoids forcing premature OWL modelling decisions.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Annotation properties\nmapsVariable = PPMI['mapsVariable']\nbridge.add((mapsVariable, RDF.type, OWL.AnnotationProperty))\nbridge.add((mapsVariable, RDFS.label, Literal('maps PPMI variable to concept IRI')))\n\nppmiVariable = PPMI['ppmiVariable']\nbridge.add((ppmiVariable, RDF.type, OWL.AnnotationProperty))\nbridge.add((ppmiVariable, RDFS.label, Literal('PPMI variable name')))\n\nmappingBucket = PPMI['mappingBucket']\nbridge.add((mappingBucket, RDF.type, OWL.AnnotationProperty))\nbridge.add((mappingBucket, RDFS.label, Literal('mapping bucket')))\n\nmappingConfidence = PPMI['mappingConfidence']\nbridge.add((mappingConfidence, RDF.type, OWL.AnnotationProperty))\nbridge.add((mappingConfidence, RDFS.label, Literal('mapping confidence')))\n\nmappingHow = PPMI['mappingHow']\nbridge.add((mappingHow, RDF.type, OWL.AnnotationProperty))\nbridge.add((mappingHow, RDFS.label, Literal('mapping notes / how')))\n\nmappingCode = PPMI['mappingCode']\nbridge.add((mappingCode, RDF.type, OWL.AnnotationProperty))\nbridge.add((mappingCode, RDFS.label, Literal('PPMI code value (if categorical)')))\n\nmappingDecode = PPMI['mappingDecode']\nbridge.add((mappingDecode, RDF.type, OWL.AnnotationProperty))\nbridge.add((mappingDecode, RDFS.label, Literal('PPMI decode label (if categorical)')))\n\ndef _clean(v):\n    if v is None:\n        return ''\n    s = str(v).strip()\n    return '' if s.lower() == 'nan' else s\n\nfor _, r in mapping.iterrows():\n    var = _clean(r.get('Variable'))\n    if not var:\n        continue\n\n    target = _clean(r.get('TargetIRI'))\n    bucket = _clean(r.get('MappingBucket'))\n    conf = _clean(r.get('Confidence'))\n    how = _clean(r.get('How'))\n    code = _clean(r.get('Code'))\n    decode = _clean(r.get('Decode'))\n\n    node = URIRef(f\"{PPMI}mapping/{var}\")\n    bridge.add((node, ppmiVariable, Literal(var)))\n    if bucket:\n        bridge.add((node, mappingBucket, Literal(bucket)))\n    if conf:\n        bridge.add((node, mappingConfidence, Literal(conf)))\n    if how:\n        bridge.add((node, mappingHow, Literal(how)))\n    if code:\n        bridge.add((node, mappingCode, Literal(code)))\n    if decode:\n        bridge.add((node, mappingDecode, Literal(decode)))\n    if target:\n        bridge.add((node, mapsVariable, URIRef(target)))\n\nprint('Bridge triples:', len(bridge))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Serialise bridge ontology\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "bridge.serialize(destination=str(OUT_PATH), format='turtle')\nprint('Wrote:', OUT_PATH)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "name": "02_build_bridge_ontology.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
